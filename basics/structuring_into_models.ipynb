{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my one of my previous [posts](https://dhruvdcoder.github.io/machinelearning/2018/03/17/linear_reg_using_gradient-mini-batch.html) we built a simple linear regression model using TensorFlow. Now, if you are working on a big project it becomes very important to structure your models in a consistent way so that they can be used with higherlevel TensorFlow API's like [tf.estimator.Estimator](https://www.tensorflow.org/programmers_guide/estimators). These highlevel APIs provide two major features:\n",
    "\n",
    "1. They provide features like [summary](https://www.tensorflow.org/api_guides/python/summary) and [checkpointing](https://www.tensorflow.org/get_started/checkpoints) without you writing any extra code.\n",
    "\n",
    "2. They keep the model and the runtime environment separated. What this means is that you can run training/evaluation/prediction on any environment (CPU, GPU, multiple GPUs) simply by changing a couple of lines in the configuration that you provide to the estimator, without making any change in your model code. More on this in the [TF Summit 2018](https://www.youtube.com/watch?v=4oNdaQk0Qv4).\n",
    "\n",
    "Also, this kind of structure will help you experiment quickly with different models by getting rid of a lot of boilerplate code. So lets get started.\n",
    "\n",
    "\n",
    "In this post I will be describing the following: \n",
    "\n",
    "1. Creating a standard model interface.  \n",
    "\n",
    "2. Using this interface to structure a linear regression model.\n",
    "\n",
    "3. Using the model with [tf.estimator.Estimator](https://www.tensorflow.org/programmers_guide/estimators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a standard model interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "# create an abstract base class\n",
    "\n",
    "\n",
    "class ModelBase(abc.ABC):\n",
    "\n",
    "    def __init__(self,  *args, **kwargs):\n",
    "        \"\"\" To store all the configuration parameters as instance attributes\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def __call__(self, features, labels, mode, params):\n",
    "        \"\"\"Create the graph, send in the input and return the appropriate tensor\n",
    "           depending on the mode\n",
    "\n",
    "           Arguments:\n",
    "               inputs:\n",
    "           Returns:\n",
    "\n",
    "           The graph has to be created only once. When the method is called the next time,\n",
    "           it should simply execute the graph on the inputs.\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            return self._call_train(features,labels)\n",
    "        elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return self._call_predict(features, labels)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return self._call_eval(features,labels)\n",
    "    \n",
    "    \n",
    "    #@abc.abstractmethod\n",
    "    #def _create_variables(self, input_shape, *args, **kwargs):\n",
    "    #    \"\"\"Used to create variables for the model. Should be called only once.\"\"\"\n",
    "    #    pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def _call_train(self, inputs, targets):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def _call_predict(self, inputs):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def _call_eval(self,inputs, targets):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Linear Regression model using the Model Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class LinearRegModel(ModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model_variable_scope = 'weights'\n",
    "        self._kernel_name = 'kernel'\n",
    "        self._bias_name = 'bias'\n",
    "        self._apply_name = 'apply'\n",
    "        self._kernel = None\n",
    "        self._bias = None\n",
    "        self._loss = lambda y_target, y_pred: tf.reduce_mean(\n",
    "            tf.square(y_target - y_pred))\n",
    "        self._optimizer = tf.train.AdamOptimizer\n",
    "        self._learning_rate = 0.001\n",
    "        self._metric = tf.metrics.root_mean_squared_error\n",
    "        self._metric_name = 'RMS'\n",
    "\n",
    "    def __call__(self, features, labels, mode, params):\n",
    "        return super().__call__(features, labels, mode, params)\n",
    "\n",
    "    def _call_predict(self, features, labels, is_internal_call=False):\n",
    "        self._create_variables(features, labels)\n",
    "        with tf.variable_scope(self._model_variable_scope, reuse=True) as scope:\n",
    "            kernel = tf.get_variable(self._kernel_name, dtype=tf.float64)\n",
    "            bias = tf.get_variable(self._bias_name, dtype=tf.float64)\n",
    "            with tf.name_scope(self._apply_name):\n",
    "                prediction = tf.add(tf.matmul(features, kernel), bias)\n",
    "        if is_internal_call:\n",
    "            return prediction\n",
    "        else:\n",
    "            mode = tf.estimator.ModeKeys.PREDICT\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=prediction)\n",
    "\n",
    "    def _call_eval(self, features, targets):\n",
    "        y_pred = self._call_predict(features, targets, is_internal_call=True)\n",
    "        loss = self._loss(targets, y_pred)\n",
    "        metric = self._metric(targets, y_pred)\n",
    "        mode = tf.estimator.ModeKeys.EVAL\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops={self._metric_name: metric})\n",
    "\n",
    "    def _call_train(self, features, targets):\n",
    "        y_pred = self._call_predict(features, targets, is_internal_call=True)\n",
    "        loss = self._loss(targets, y_pred)\n",
    "        training_op = self._optimizer(\n",
    "            learning_rate=self._learning_rate).minimize(loss, global_step=tf.train.get_global_step())\n",
    "        mode = tf.estimator.ModeKeys.TRAIN\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=training_op)\n",
    "\n",
    "    def _infer_num_features(self, features):\n",
    "        features_shape = features.get_shape()\n",
    "        n_features = features_shape[1].value\n",
    "        return n_features\n",
    "\n",
    "    def _infer_num_labels(self, labels):\n",
    "        label_shape = labels.get_shape()\n",
    "        n_labels = 1\n",
    "        if len(label_shape) > 1:\n",
    "            n_labels = label_shape[1].value\n",
    "        return n_labels\n",
    "\n",
    "    def _create_variables(self, features, labels, *args, **kwargs):\n",
    "        n_features = self._infer_num_features(features)\n",
    "        n_labels = 1\n",
    "        if labels is not None:\n",
    "            n_labels = self._infer_num_labels(labels)\n",
    "        with tf.variable_scope(self._model_variable_scope) as scope:\n",
    "            self._kernel = tf.get_variable(name=self._kernel_name, initializer=tf.random_uniform(\n",
    "                shape=[n_features, 1], dtype=tf.float64))\n",
    "            self._bias = tf.get_variable(\n",
    "                name=self._bias_name, initializer=tf.random_uniform([1], dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Linear Regression model with `tf.estimator.Estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data=fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaled_features=scaler.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.7\n",
    "import numpy as np\n",
    "((train_features, test_features), (train_y, test_y)) = (map(lambda x: np.split(\n",
    "        x, [int(np.ceil(train_test_ratio*len(x)))]), (scaled_features, data.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, targets, batch_size):\n",
    "    #create a Dataset object\n",
    "    with tf.name_scope('train_input_pipline'):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((features,targets))\n",
    "        # repeat infinitely, shuffle and batch the data\n",
    "        dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(features, targets, batch_size):\n",
    "    with tf.name_scope('eval_input_pipeline'):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((features, targets))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model using LinearRegModel\n",
    "model = LinearRegModel()\n",
    "max_steps = 1000\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_session_config': None, '_num_ps_replicas': 0, '_evaluation_master': '', '_master': '', '_service': None, '_global_id_in_cluster': 0, '_task_id': 0, '_num_worker_replicas': 1, '_is_chief': True, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_model_dir': 'temp/LinearReg', '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f503b878128>}\n",
      "WARNING:tensorflow:Estimator's model_fn (<__main__.LinearRegModel object at 0x7f503b878be0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn=model, model_dir='temp/LinearReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into temp/LinearReg/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 6.863418841271151\n",
      "INFO:tensorflow:global_step/sec: 39.6945\n",
      "INFO:tensorflow:step = 101, loss = 3.5302526225355915 (2.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9672\n",
      "INFO:tensorflow:step = 201, loss = 3.123366159133359 (2.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.4224\n",
      "INFO:tensorflow:step = 301, loss = 4.016394770009598 (2.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.403\n",
      "INFO:tensorflow:step = 401, loss = 2.2798705590292294 (2.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.1189\n",
      "INFO:tensorflow:step = 501, loss = 4.009098033533354 (2.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.745\n",
      "INFO:tensorflow:step = 601, loss = 2.7471322699039638 (2.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.5201\n",
      "INFO:tensorflow:step = 701, loss = 2.498856832694869 (2.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.168\n",
      "INFO:tensorflow:step = 801, loss = 3.3191915006332886 (2.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.7604\n",
      "INFO:tensorflow:step = 901, loss = 0.8954406073728375 (2.515 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into temp/LinearReg/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.0981980166387473.\n"
     ]
    }
   ],
   "source": [
    "trained = estimator.train(lambda:train_input_fn(train_features,train_y,batch_size), max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-31-11:59:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from temp/LinearReg/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-31-11:59:58\n",
      "INFO:tensorflow:Saving dict for global step 1000: RMS = 1.6993942, global_step = 1000, loss = 2.927359\n"
     ]
    }
   ],
   "source": [
    "evaluated = estimator.evaluate(lambda:eval_input_fn(test_features,test_y,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
